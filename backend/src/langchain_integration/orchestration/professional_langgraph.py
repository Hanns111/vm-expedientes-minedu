"""
LangGraph PROFESIONAL con arquitectura robusta, trazable y escalable
Combina tu implementaci√≥n actual con mejores pr√°cticas de ChatGPT
"""
import logging
import time
from typing import Dict, Any, List, Optional, TypedDict, Annotated
from datetime import datetime
import operator
import re

# LangGraph REAL imports
from langgraph.graph import StateGraph, MessagesState, START, END
from langgraph.graph.message import add_messages
from langgraph.checkpoint.memory import MemorySaver
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain.memory import ConversationBufferMemory

from ..agents.viaticos_agent import viaticos_agent
from ..config import config

logger = logging.getLogger(__name__)

# === ESTADO PROFESIONAL LANGGRAPH ===
class ProfessionalRAGState(TypedDict):
    """Estado completo para RAG profesional con validaci√≥n y fallback"""
    # Mensajes y conversaci√≥n
    messages: Annotated[List, add_messages]
    query: str
    conversation_memory: Dict[str, Any]
    
    # An√°lisis de intenci√≥n
    intent: str
    intent_confidence: float
    intent_entities: Dict[str, Any]
    
    # Routing y agentes
    selected_agent: str
    agent_attempts: int
    max_attempts: int
    
    # Procesamiento y validaci√≥n
    raw_response: str
    validated_response: bool
    validation_errors: List[str]
    evidence_found: List[str]
    
    # Fuentes y metadatos
    sources: List[Dict[str, Any]]
    documents_found: int
    confidence: float
    
    # Fallback y composici√≥n
    used_fallback: bool
    fallback_reason: str
    final_response: str
    
    # Observabilidad
    processing_time: float
    timestamp: str
    trace_id: str
    node_history: List[str]
    error_log: List[str]

class ProfessionalLangGraphOrchestrator:
    """Orquestador LangGraph PROFESIONAL con validaci√≥n, retry y observabilidad"""
    
    def __init__(self):
        self.orchestrator_name = "professional_langgraph"
        
        # Agentes especializados
        self.agents = {
            "viaticos": viaticos_agent,
            # Escalable a: "detracciones", "siaf", "snip", etc.
        }
        
        # Patrones de validaci√≥n para respuestas
        self.validation_patterns = {
            "viaticos": [
                r"S/\s*\d+\.?\d*",  # Montos en soles
                r"\d+\.?\d*\s*soles",  # Soles escritos
                r"art√≠culo\s*\d+",  # Referencias normativas
                r"directiva\s*\d+",  # Directivas
            ],
            "declaracion_jurada": [
                r"declaraci√≥n\s*jurada",
                r"sin\s*comprobante",
                r"l√≠mite|limite",
            ]
        }
        
        # Memoria de conversaci√≥n
        self.conversation_memory = ConversationBufferMemory(
            memory_key="chat_history",
            return_messages=True,
            max_token_limit=2000
        )
        
        # Construir StateGraph profesional
        self.workflow = self._build_professional_stategraph()
        
        # Memory saver para checkpointing
        self.memory = MemorySaver()
        
        # Compilar graph
        self.compiled_graph = self.workflow.compile(checkpointer=self.memory)
        
        logger.info("üöÄ LangGraph PROFESIONAL inicializado con validaci√≥n y retry")
    
    def _build_professional_stategraph(self) -> StateGraph:
        """Construir StateGraph profesional con nodos de validaci√≥n y fallback"""
        
        workflow = StateGraph(ProfessionalRAGState)
        
        # === NODOS PROFESIONALES ===
        workflow.add_node("input_validation", self._input_validation_node)
        workflow.add_node("detect_intent", self._detect_intent_node)
        workflow.add_node("route_to_agent", self._route_to_agent_node)
        workflow.add_node("execute_agent", self._execute_agent_node)
        workflow.add_node("validate_response", self._validate_response_node)
        workflow.add_node("fallback_legacy", self._fallback_legacy_node)
        workflow.add_node("compose_response", self._compose_response_node)
        workflow.add_node("error_handler", self._error_handler_node)
        
        # === FLUJO PRINCIPAL ===
        workflow.add_edge(START, "input_validation")
        workflow.add_edge("input_validation", "detect_intent")
        workflow.add_edge("detect_intent", "route_to_agent")
        workflow.add_edge("route_to_agent", "execute_agent")
        
        # === CONDITIONAL EDGES CON VALIDACI√ìN ===
        workflow.add_conditional_edges(
            "execute_agent",
            self._decide_after_agent,
            {
                "validate": "validate_response",
                "retry": "execute_agent",
                "error": "error_handler"
            }
        )
        
        workflow.add_conditional_edges(
            "validate_response",
            self._decide_after_validation,
            {
                "success": "compose_response",
                "fallback": "fallback_legacy",
                "retry": "execute_agent"
            }
        )
        
        workflow.add_edge("fallback_legacy", "compose_response")
        workflow.add_edge("compose_response", END)
        workflow.add_edge("error_handler", END)
        
        return workflow
    
    # === NODOS PROFESIONALES ===
    
    async def _input_validation_node(self, state: ProfessionalRAGState) -> ProfessionalRAGState:
        """Validaci√≥n robusta de entrada"""
        start_time = time.time()
        node_name = "input_validation"
        
        try:
            query = state["query"].strip()
            
            # Validaciones de seguridad
            validation_errors = []
            
            # 1. Longitud m√≠nima/m√°xima
            if len(query) < 3:
                validation_errors.append("Query demasiado corta")
            elif len(query) > 500:
                validation_errors.append("Query demasiado larga")
            
            # 2. Caracteres maliciosos b√°sicos
            malicious_patterns = [
                r"<script",
                r"javascript:",
                r"eval\(",
                r"exec\(",
                r"__import__"
            ]
            
            for pattern in malicious_patterns:
                if re.search(pattern, query, re.IGNORECASE):
                    validation_errors.append(f"Patr√≥n malicioso detectado: {pattern}")
            
            # 3. Solo espacios o caracteres especiales
            if not re.search(r"[a-zA-Z√°√©√≠√≥√∫√Å√â√ç√ì√ö√±√ë]", query):
                validation_errors.append("Query sin contenido textual v√°lido")
            
            # Actualizar estado
            state["validation_errors"] = validation_errors
            state["trace_id"] = f"trace_{int(time.time())}"
            state["node_history"] = [node_name]
            state["max_attempts"] = 3
            state["agent_attempts"] = 0
            
            if validation_errors:
                state["error_log"] = validation_errors
                logger.warning(f"‚ùå [{node_name}] Errores de validaci√≥n: {validation_errors}")
            else:
                logger.info(f"‚úÖ [{node_name}] Input v√°lido: '{query[:50]}...'")
            
            return state
            
        except Exception as e:
            logger.error(f"‚ùå [{node_name}] Error: {e}")
            state["error_log"] = [f"Error en {node_name}: {str(e)}"]
            return state
    
    async def _detect_intent_node(self, state: ProfessionalRAGState) -> ProfessionalRAGState:
        """Detecci√≥n avanzada de intenci√≥n con entidades"""
        node_name = "detect_intent"
        state["node_history"].append(node_name)
        
        try:
            query = state["query"].lower()
            
            # Patrones mejorados de intenci√≥n
            intent_patterns = {
                "viaticos": {
                    "patterns": ["vi√°tico", "viaticos", "vi√°ticos", "monto", "gastos", "comisi√≥n"],
                    "entities": {
                        "amount": r"(s/\s*\d+\.?\d*|\d+\.?\d*\s*soles)",
                        "location": r"(lima|provincia|provincias|metropolitana|regional)",
                        "type": r"(declaraci√≥n jurada|sin comprobante|con comprobante)"
                    }
                },
                "declaracion_jurada": {
                    "patterns": ["declaraci√≥n jurada", "declaracion jurada", "sin comprobante"],
                    "entities": {
                        "limit": r"(l√≠mite|limite|m√°ximo|maximo|tope)",
                        "location": r"(lima|provincia|provincias)"
                    }
                }
            }
            
            # Calcular scores de intenci√≥n
            intent_scores = {}
            entities_found = {}
            
            for intent, config in intent_patterns.items():
                score = 0
                entities = {}
                
                # Score por patrones
                for pattern in config["patterns"]:
                    if pattern in query:
                        score += len(pattern) * 2  # Peso por longitud
                
                # Extraer entidades
                for entity_type, entity_pattern in config["entities"].items():
                    matches = re.findall(entity_pattern, query, re.IGNORECASE)
                    if matches:
                        entities[entity_type] = matches
                        score += len(matches) * 3  # Bonus por entidades
                
                if score > 0:
                    intent_scores[intent] = score
                    entities_found[intent] = entities
            
            # Determinar intenci√≥n principal
            if intent_scores:
                primary_intent = max(intent_scores.keys(), key=lambda x: intent_scores[x])
                confidence = min(intent_scores[primary_intent] / 15, 1.0)
                intent_entities = entities_found.get(primary_intent, {})
            else:
                primary_intent = "general"
                confidence = 0.2
                intent_entities = {}
            
            # Actualizar estado
            state["intent"] = primary_intent
            state["intent_confidence"] = confidence
            state["intent_entities"] = intent_entities
            
            logger.info(f"üß† [{node_name}] Intent: {primary_intent} (conf: {confidence:.2f})")
            logger.info(f"üéØ [{node_name}] Entidades: {intent_entities}")
            
            return state
            
        except Exception as e:
            logger.error(f"‚ùå [{node_name}] Error: {e}")
            state["error_log"].append(f"Error en {node_name}: {str(e)}")
            return state
    
    async def _route_to_agent_node(self, state: ProfessionalRAGState) -> ProfessionalRAGState:
        """Routing inteligente a agentes especializados"""
        node_name = "route_to_agent"
        state["node_history"].append(node_name)
        
        try:
            intent = state["intent"]
            confidence = state["intent_confidence"]
            
            # L√≥gica de routing mejorada
            if confidence > 0.6 and intent in self.agents:
                selected_agent = intent
            elif confidence > 0.3 and intent in self.agents:
                selected_agent = intent  # Intentar con confianza media
            else:
                selected_agent = "viaticos"  # Agente por defecto
            
            state["selected_agent"] = selected_agent
            
            logger.info(f"üö¶ [{node_name}] Routing: {state['query'][:30]}... ‚Üí {selected_agent}")
            
            return state
            
        except Exception as e:
            logger.error(f"‚ùå [{node_name}] Error: {e}")
            state["error_log"].append(f"Error en {node_name}: {str(e)}")
            return state
    
    async def _execute_agent_node(self, state: ProfessionalRAGState) -> ProfessionalRAGState:
        """Ejecuci√≥n de agente con retry autom√°tico"""
        node_name = "execute_agent"
        state["node_history"].append(node_name)
        
        try:
            selected_agent = state["selected_agent"]
            state["agent_attempts"] += 1
            
            logger.info(f"ü§ñ [{node_name}] Ejecutando {selected_agent} (intento {state['agent_attempts']})")
            
            # Ejecutar agente real
            agent = self.agents[selected_agent]
            agent_result = await agent.process_query(state["query"])
            
            # Extraer informaci√≥n del resultado
            raw_response = agent_result.get("response", "")
            sources = agent_result.get("sources", [])
            documents_found = agent_result.get("documents_found", 0)
            confidence = agent_result.get("confidence", 0.0)
            
            # üöÄ ENTERPRISE ENHANCEMENT: Advanced Reranking
            try:
                if sources and len(sources) > 1:
                    logger.info(f"üîÑ [{node_name}] Aplicando reranking avanzado a {len(sources)} documentos")
                    
                    # Importar reranker (usando path relativo correcto)
                    try:
                        from ...core.reranking.advanced_reranker import rerank_search_results
                    except ImportError:
                        # Fallback import
                        import sys
                        from pathlib import Path
                        backend_dir = Path(__file__).parent.parent.parent.parent
                        sys.path.insert(0, str(backend_dir / "src"))
                        from core.reranking.advanced_reranker import rerank_search_results
                    
                    # Preparar documentos para reranking
                    documents_for_rerank = []
                    for i, source in enumerate(sources):
                        doc = {
                            "id": str(i),
                            "content": source.get("content", ""),
                            "text": source.get("content", ""),  # Fallback
                            "score": source.get("score", 0.5),
                            "source": source.get("source", ""),
                            "title": source.get("title", "")
                        }
                        documents_for_rerank.append(doc)
                    
                    # Aplicar reranking h√≠brido
                    reranked_results = await rerank_search_results(
                        query=state["query"],
                        documents=documents_for_rerank,
                        strategy="hybrid"  # hybrid, cross_encoder, semantic, fallback
                    )
                    
                    if reranked_results:
                        # Actualizar sources con resultados reranqueados
                        reranked_sources = []
                        for result in reranked_results:
                            reranked_source = {
                                "content": result.content,
                                "source": result.metadata.get("source", ""),
                                "title": result.metadata.get("title", ""),
                                "score": result.reranked_score,
                                "original_score": result.original_score,
                                "confidence": result.confidence,
                                "ranking_method": result.ranking_method,
                                "original_rank": result.metadata.get("original_rank", 0)
                            }
                            reranked_sources.append(reranked_source)
                        
                        sources = reranked_sources
                        
                        # Actualizar confianza basada en reranking
                        if reranked_results:
                            top_confidence = reranked_results[0].confidence
                            confidence = max(confidence, top_confidence)  # Tomar la mejor confianza
                        
                        logger.info(f"‚úÖ [{node_name}] Reranking completado: top score {reranked_results[0].reranked_score:.3f}, m√©todo: {reranked_results[0].ranking_method}")
                    else:
                        logger.warning(f"‚ö†Ô∏è [{node_name}] Reranking no produjo resultados, usando originales")
                        
                else:
                    logger.info(f"‚ÑπÔ∏è [{node_name}] Reranking omitido: {len(sources)} documentos disponibles")
                    
            except Exception as rerank_error:
                logger.warning(f"‚ö†Ô∏è [{node_name}] Error en reranking: {rerank_error}, continuando con documentos originales")
                # Continuar con documentos originales si el reranking falla
            
            # Actualizar estado
            state["raw_response"] = raw_response
            state["sources"] = sources
            state["documents_found"] = documents_found
            state["confidence"] = confidence
            
            # Agregar mensaje AI
            ai_message = AIMessage(content=raw_response)
            state["messages"].append(ai_message)
            
            logger.info(f"‚úÖ [{node_name}] Agente completado: {len(raw_response)} chars, {documents_found} docs")
            
            return state
            
        except Exception as e:
            logger.error(f"‚ùå [{node_name}] Error: {e}")
            state["error_log"].append(f"Error en {node_name}: {str(e)}")
            state["raw_response"] = ""
            return state
    
    async def _validate_response_node(self, state: ProfessionalRAGState) -> ProfessionalRAGState:
        """Validaci√≥n robusta de respuesta con evidencia"""
        node_name = "validate_response"
        state["node_history"].append(node_name)
        
        try:
            raw_response = state["raw_response"]
            intent = state["intent"]
            
            validation_errors = []
            evidence_found = []
            
            # 1. Validaci√≥n b√°sica
            if not raw_response or len(raw_response.strip()) < 10:
                validation_errors.append("Respuesta vac√≠a o muy corta")
            
            # 2. Validaci√≥n espec√≠fica por intenci√≥n
            if intent in self.validation_patterns:
                patterns = self.validation_patterns[intent]
                pattern_matches = 0
                
                for pattern in patterns:
                    matches = re.findall(pattern, raw_response, re.IGNORECASE)
                    if matches:
                        pattern_matches += 1
                        evidence_found.extend(matches)
                
                if pattern_matches == 0:
                    validation_errors.append(f"No se encontr√≥ evidencia espec√≠fica para {intent}")
            
            # 3. Validaci√≥n de fuentes
            if state["documents_found"] == 0:
                validation_errors.append("No se encontraron documentos de respaldo")
            elif state["confidence"] < 0.5:
                validation_errors.append("Confianza muy baja en la respuesta")
            
            # 4. Validaci√≥n de contenido malicioso en respuesta
            malicious_in_response = [
                r"error|exception|traceback",
                r"none|null|undefined",
                r"<script|javascript:"
            ]
            
            for pattern in malicious_in_response:
                if re.search(pattern, raw_response, re.IGNORECASE):
                    validation_errors.append(f"Contenido problem√°tico en respuesta")
            
            # Actualizar estado
            state["validation_errors"] = validation_errors
            state["evidence_found"] = evidence_found
            state["validated_response"] = len(validation_errors) == 0
            
            if validation_errors:
                logger.critical(f"‚ö†Ô∏è [{node_name}] ERRORES CR√çTICOS DE VALIDACI√ìN: {validation_errors}")
                # TODO: Implementar sistema de respuesta segura para errores de validaci√≥n
            else:
                logger.info(f"‚úÖ [{node_name}] Respuesta v√°lida con evidencia: {evidence_found}")
            
            return state
            
        except Exception as e:
            logger.error(f"‚ùå [{node_name}] Error: {e}")
            state["error_log"].append(f"Error en {node_name}: {str(e)}")
            state["validated_response"] = False
            return state
    
    async def _fallback_legacy_node(self, state: ProfessionalRAGState) -> ProfessionalRAGState:
        """Sistema de fallback con respuestas de emergencia"""
        node_name = "fallback_legacy"
        state["node_history"].append(node_name)
        
        try:
            logger.critical("‚ö†Ô∏è FALLBACK ACTIVADO - No se encontr√≥ informaci√≥n en documentos oficiales")
            # TODO: Reemplazar fallback con consulta real a base de datos normativa
            query = state["query"].lower()
            intent = state["intent"]
            
            # Fallbacks espec√≠ficos por dominio - SOLO PARA EMERGENCIA
            fallback_responses = {
                "viaticos": {
                    "monto": """üìã **CONSULTA DE VI√ÅTICOS:**
                    
‚ö†Ô∏è **INFORMACI√ìN NO DISPONIBLE:**
‚Ä¢ Los montos espec√≠ficos deben consultarse en la normativa vigente
‚Ä¢ Consulte la Directiva N¬∞ 011-2020-MINEDU para informaci√≥n exacta

üìû **RECOMENDACI√ìN:** Contacte directamente al √°rea administrativa para obtener los montos actualizados.""",
                    
                    "procedimiento": """üìã **PROCEDIMIENTO GENERAL PARA VI√ÅTICOS:**

üìù **PASOS B√ÅSICOS:**
1. Solicitud con 5 d√≠as de anticipaci√≥n
2. Aprobaci√≥n del jefe inmediato
3. Asignaci√≥n seg√∫n escala vigente
4. Rendici√≥n en 10 d√≠as h√°biles

‚ö†Ô∏è **NOTA:** Consulte la Directiva N¬∞ 011-2020-MINEDU para procedimiento completo."""
                }
            }
            
            # Determinar tipo de fallback
            fallback_type = "general"
            if "monto" in query or "cuanto" in query or "s/" in query:
                fallback_type = "monto"
            elif "procedimiento" in query or "como" in query or "pasos" in query:
                fallback_type = "procedimiento"
            
            # Obtener respuesta de fallback
            if intent in fallback_responses and fallback_type in fallback_responses[intent]:
                fallback_response = fallback_responses[intent][fallback_type]
            else:
                logger.critical("‚ö†Ô∏è Fallback general activado - consulta sin informaci√≥n documental disponible")
                # TODO: Implementar b√∫squeda avanzada en base de datos normativa
                fallback_response = """üìã **CONSULTA RECIBIDA:**

‚ùå No se encontr√≥ informaci√≥n espec√≠fica en los documentos oficiales disponibles.

üîç **ESTADO DEL SISTEMA:**
‚Ä¢ Base de datos consultada: Documentos normativos MINEDU
‚Ä¢ Resultado: Sin coincidencias verificables

üí° **RECOMENDACIONES:**
‚Ä¢ Reformule su consulta con t√©rminos oficiales espec√≠ficos
‚Ä¢ Consulte directamente las directivas vigentes del MINEDU
‚Ä¢ Contacte al √°rea administrativa correspondiente

‚ö†Ô∏è **IMPORTANTE:** Este sistema solo proporciona informaci√≥n basada en documentos oficiales verificados."""
            
            # Actualizar estado
            state["raw_response"] = fallback_response
            state["used_fallback"] = True
            state["fallback_reason"] = f"Validaci√≥n fall√≥: {state.get('validation_errors', [])}"
            
            # Agregar mensaje de fallback
            fallback_message = AIMessage(content=fallback_response)
            state["messages"].append(fallback_message)
            
            logger.critical(f"üîÑ [{node_name}] FALLBACK CR√çTICO ACTIVADO: {fallback_type} - sistema sin datos documentales")
            
            return state
            
        except Exception as e:
            logger.error(f"‚ùå [{node_name}] Error: {e}")
            state["error_log"].append(f"Error en {node_name}: {str(e)}")
            return state
    
    async def _compose_response_node(self, state: ProfessionalRAGState) -> ProfessionalRAGState:
        """Composici√≥n final de respuesta con metadatos"""
        node_name = "compose_response"
        state["node_history"].append(node_name)
        
        try:
            raw_response = state["raw_response"]
            
            # Agregar metadatos de transparencia
            response_footer = f"""

---
üìä **METADATOS DEL SISTEMA:**
‚Ä¢ Agente: {state.get('selected_agent', 'N/A')}
‚Ä¢ Documentos consultados: {state.get('documents_found', 0)}
‚Ä¢ Confianza: {state.get('confidence', 0):.1%}
‚Ä¢ Fallback usado: {'S√≠' if state.get('used_fallback') else 'No'}
‚Ä¢ Trace ID: {state.get('trace_id', 'N/A')}"""
            
            final_response = raw_response + response_footer
            
            # Actualizar estado final
            state["final_response"] = final_response
            state["timestamp"] = datetime.now().isoformat()
            state["processing_time"] = time.time() - float(state["trace_id"].split("_")[1])
            
            logger.info(f"üìù [{node_name}] Respuesta final compuesta: {len(final_response)} chars")
            
            return state
            
        except Exception as e:
            logger.error(f"‚ùå [{node_name}] Error: {e}")
            state["error_log"].append(f"Error en {node_name}: {str(e)}")
            state["final_response"] = state.get("raw_response", "Error procesando respuesta")
            return state
    
    async def _error_handler_node(self, state: ProfessionalRAGState) -> ProfessionalRAGState:
        """Manejo robusto de errores"""
        node_name = "error_handler"
        state["node_history"].append(node_name)
        
        try:
            error_log = state.get("error_log", [])
            
            # TODO: Implementar sistema de respuesta de error seguro para producci√≥n
            logger.critical(f"‚ö†Ô∏è SISTEMA EN ERROR - m√∫ltiples fallos detectados: {len(error_log)} errores")
            
            error_response = f"""‚ùå **CONSULTA NO DISPONIBLE:**

üîç **ESTADO DEL SISTEMA:**
‚Ä¢ El sistema no puede procesar la consulta en este momento
‚Ä¢ Se han consultado las bases de datos oficiales disponibles

üÜò **RECOMENDACIONES:**
‚Ä¢ Reformule su consulta con t√©rminos m√°s espec√≠ficos
‚Ä¢ Consulte directamente las directivas vigentes del MINEDU
‚Ä¢ Contacte al √°rea administrativa correspondiente

üìû **SOPORTE:** √Årea de Sistemas - Administraci√≥n MINEDU
‚è∞ **FECHA:** {datetime.now().strftime('%d/%m/%Y %H:%M')}"""
            
            state["final_response"] = error_response
            state["timestamp"] = datetime.now().isoformat()
            
            logger.critical(f"üí• [{node_name}] Error del sistema manejado - {len(error_log)} errores registrados")
            
            return state
            
        except Exception as e:
            logger.critical(f"‚ùå [{node_name}] Error cr√≠tico en manejo de errores: {e}")
            state["final_response"] = "Error cr√≠tico del sistema. Contacte al administrador."
            return state
    
    # === FUNCIONES DE DECISI√ìN ===
    
    def _decide_after_agent(self, state: ProfessionalRAGState) -> str:
        """Decidir siguiente paso despu√©s de ejecutar agente"""
        try:
            # Si hay errores en el log, manejar error
            if state.get("error_log") and any("Error en execute_agent" in error for error in state["error_log"]):
                if state["agent_attempts"] < state["max_attempts"]:
                    logger.info(f"üîÑ Retry agente: intento {state['agent_attempts']}/{state['max_attempts']}")
                    return "retry"
                else:
                    logger.warning(f"üí• Max intentos alcanzados, enviando a error handler")
                    return "error"
            
            # Si la respuesta est√° vac√≠a, retry o error
            if not state.get("raw_response", "").strip():
                if state["agent_attempts"] < state["max_attempts"]:
                    return "retry"
                else:
                    return "error"
            
            # Continuar con validaci√≥n
            return "validate"
            
        except Exception as e:
            logger.error(f"Error en decisi√≥n post-agente: {e}")
            return "error"
    
    def _decide_after_validation(self, state: ProfessionalRAGState) -> str:
        """Decidir siguiente paso despu√©s de validar respuesta"""
        try:
            validated = state.get("validated_response", False)
            validation_errors = state.get("validation_errors", [])
            
            # Si la validaci√≥n es exitosa
            if validated:
                logger.info("‚úÖ Validaci√≥n exitosa, componiendo respuesta")
                return "success"
            
            # Si hay errores cr√≠ticos y ya agotamos intentos
            if state["agent_attempts"] >= state["max_attempts"]:
                logger.warning("‚ö†Ô∏è Max intentos alcanzados, usando fallback")
                return "fallback"
            
            # Si son errores de contenido (no t√©cnicos), usar fallback
            content_errors = ["No se encontr√≥ evidencia", "Confianza muy baja", "No se encontraron documentos"]
            has_content_errors = any(any(content_error in error for content_error in content_errors) 
                                   for error in validation_errors)
            
            if has_content_errors:
                logger.info("üîÑ Errores de contenido, usando fallback")
                return "fallback"
            
            # Para otros errores, retry
            logger.info("üîÑ Errores t√©cnicos, reintentando agente")
            return "retry"
            
        except Exception as e:
            logger.error(f"Error en decisi√≥n post-validaci√≥n: {e}")
            return "fallback"
    
    # === API PRINCIPAL ===
    
    async def process_query_professional(self, query: str, thread_id: str = None) -> Dict[str, Any]:
        """Procesar consulta con LangGraph profesional"""
        start_time = time.time()
        
        if not thread_id:
            thread_id = f"prof_{int(time.time())}"
        
        try:
            logger.info(f"üöÄ [PROFESSIONAL] Procesando: {query[:50]}...")
            
            # Estado inicial profesional
            initial_state = {
                "messages": [HumanMessage(content=query)],
                "query": query,
                "conversation_memory": {},
                "intent": "",
                "intent_confidence": 0.0,
                "intent_entities": {},
                "selected_agent": "",
                "agent_attempts": 0,
                "max_attempts": 3,
                "raw_response": "",
                "validated_response": False,
                "validation_errors": [],
                "evidence_found": [],
                "sources": [],
                "documents_found": 0,
                "confidence": 0.0,
                "used_fallback": False,
                "fallback_reason": "",
                "final_response": "",
                "processing_time": 0.0,
                "timestamp": "",
                "trace_id": "",
                "node_history": [],
                "error_log": []
            }
            
            # Configuraci√≥n de thread
            config_thread = {"configurable": {"thread_id": thread_id}}
            
            # ¬°EJECUTAR LANGGRAPH PROFESIONAL!
            final_state = await self.compiled_graph.ainvoke(
                initial_state,
                config=config_thread
            )
            
            # Calcular tiempo total
            total_time = time.time() - start_time
            
            # Resultado profesional
            result = {
                "response": final_state.get("final_response", ""),
                "sources": final_state.get("sources", []),
                "confidence": final_state.get("confidence", 0.0),
                "documents_found": final_state.get("documents_found", 0),
                "intent": final_state.get("intent", ""),
                "intent_entities": final_state.get("intent_entities", {}),
                "extracted_info": {
                    "evidence_found": final_state.get("evidence_found", []),
                    "validation_errors": final_state.get("validation_errors", []),
                    "used_fallback": final_state.get("used_fallback", False),
                    "fallback_reason": final_state.get("fallback_reason", ""),
                    "agent_attempts": final_state.get("agent_attempts", 0)
                },
                "processing_time": round(total_time, 3),
                "method": "professional_langgraph",
                "agent_used": final_state.get("selected_agent", ""),
                "orchestrator_info": {
                    "orchestrator": self.orchestrator_name,
                    "thread_id": thread_id,
                    "trace_id": final_state.get("trace_id", ""),
                    "node_history": final_state.get("node_history", []),
                    "total_processing_time": round(total_time, 3),
                    "timestamp": datetime.now().isoformat(),
                    "langgraph_professional": True,
                    "validation_enabled": True,
                    "retry_enabled": True,
                    "fallback_enabled": True
                }
            }
            
            logger.info(f"‚úÖ [PROFESSIONAL] Completado en {total_time:.3f}s")
            logger.info(f"üìä [PROFESSIONAL] Nodos: {final_state.get('node_history', [])}")
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå [PROFESSIONAL] Error cr√≠tico: {e}")
            return {
                "response": f"Error cr√≠tico en LangGraph profesional: {str(e)}",
                "sources": [],
                "confidence": 0.0,
                "error": str(e),
                "method": "professional_langgraph_error",
                "orchestrator_info": {
                    "orchestrator": self.orchestrator_name,
                    "error": True,
                    "timestamp": datetime.now().isoformat()
                }
            }
    
    def get_system_status(self) -> Dict[str, Any]:
        """Estado del sistema profesional"""
        try:
            from ..vectorstores.simple_retriever import retriever
            retriever_stats = retriever.get_stats()
            
            return {
                "orchestrator": self.orchestrator_name,
                "status": "professional_operational",
                "langgraph_version": "professional",
                "features": {
                    "input_validation": True,
                    "intent_detection": True,
                    "agent_routing": True,
                    "response_validation": True,
                    "automatic_retry": True,
                    "fallback_system": True,
                    "conversation_memory": True,
                    "observability": True,
                    "error_handling": True
                },
                "agents": {name: {"available": True, "type": type(agent).__name__} 
                          for name, agent in self.agents.items()},
                "validation_patterns": list(self.validation_patterns.keys()),
                "max_retry_attempts": 3,
                "retriever_stats": retriever_stats,
                "checkpointing": True,
                "memory_saver": True,
                "timestamp": datetime.now().isoformat()
            }
        except Exception as e:
            return {
                "orchestrator": self.orchestrator_name,
                "status": "error",
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }

# Instancia global profesional
professional_orchestrator = ProfessionalLangGraphOrchestrator()