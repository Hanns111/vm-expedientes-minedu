#!/usr/bin/env python3
"""
Script de Extracci√≥n Mejorada con Integraci√≥n de Pipeline
========================================================

Mejora los resultados de PaddleOCR con extracci√≥n robusta de tablas
para encontrar los montos espec√≠ficos de vi√°ticos.
"""

import argparse
import json
import logging
import time
from pathlib import Path
from typing import Dict, List, Any, Optional

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def enhanced_extraction(pdf_path: str, ocr_results: Optional[Dict] = None) -> Dict[str, Any]:
    """
    Mejora los resultados de PaddleOCR con extracci√≥n de tablas
    
    Args:
        pdf_path: Ruta al archivo PDF
        ocr_results: Resultados existentes de PaddleOCR (opcional)
    
    Returns:
        Diccionario con chunks mejorados
    """
    logger.info(f"üöÄ Iniciando extracci√≥n mejorada para: {pdf_path}")
    
    # Verificar que el archivo existe
    if not Path(pdf_path).exists():
        logger.error(f"‚ùå Archivo no encontrado: {pdf_path}")
        return {"error": "Archivo no encontrado", "chunks": []}
    
    # 1. Usar resultados existentes de PaddleOCR si est√°n disponibles
    base_text = ""
    ocr_chunks = []
    
    if ocr_results:
        base_text = ocr_results.get('text', '')
        ocr_chunks = ocr_results.get('chunks', [])
        logger.info(f"üìÑ Usando {len(ocr_chunks)} chunks existentes de OCR")
    else:
        logger.info("üìÑ No hay resultados de OCR previos, extrayendo solo tablas")
    
    # 2. Extraer tablas con el extractor robusto
    try:
        from src.ocr_pipeline.extractors.robust_table_extractor import RobustTableExtractor
        
        extractor = RobustTableExtractor(
            use_opencv_preprocessing=True,
            preprocessing_params={
                'threshold_type': 'adaptive',  # Mejor para PDFs escaneados
                'blur_kernel': (5, 5),
                'dilate_iterations': 2
            }
        )
        
        # Configurar logging detallado
        logging.getLogger('src.ocr_pipeline.extractors.robust_table_extractor').setLevel(logging.DEBUG)
        
        logger.info("üîç Extrayendo tablas...")
        start_time = time.time()
        
        table_chunks = extractor.extract_from_pdf(pdf_path)
        
        extraction_time = time.time() - start_time
        logger.info(f"‚è±Ô∏è  Extracci√≥n completada en {extraction_time:.3f}s")
        logger.info(f"üìä {len(table_chunks)} chunks de tablas extra√≠dos")
        
    except ImportError as e:
        logger.error(f"‚ùå Error importando extractor: {e}")
        logger.error("üí° Instalar dependencias: pip install camelot-py[cv] pdfplumber")
        return {"error": "Dependencias faltantes", "chunks": ocr_chunks}
    
    except Exception as e:
        logger.error(f"‚ùå Error en extracci√≥n de tablas: {e}")
        return {"error": str(e), "chunks": ocr_chunks}
    
    # 3. Fusionar con chunks existentes
    enhanced_chunks = merge_with_existing_chunks(ocr_chunks, table_chunks)
    
    # 4. Validar montos objetivo
    validation_results = validate_target_amounts(enhanced_chunks)
    
    # 5. Generar reporte
    report = generate_extraction_report(
        pdf_path, len(ocr_chunks), len(table_chunks), 
        len(enhanced_chunks), validation_results, extraction_time
    )
    
    return {
        "success": True,
        "chunks": enhanced_chunks,
        "validation": validation_results,
        "report": report,
        "stats": {
            "ocr_chunks": len(ocr_chunks),
            "table_chunks": len(table_chunks),
            "total_chunks": len(enhanced_chunks),
            "extraction_time": extraction_time
        }
    }

def merge_with_existing_chunks(ocr_chunks: List[Dict], table_chunks: List[Dict]) -> List[Dict]:
    """Fusionar chunks de OCR con chunks de tablas"""
    
    logger.info(f"üîÑ Fusionando {len(ocr_chunks)} chunks OCR + {len(table_chunks)} chunks tablas")
    
    # Comenzar con chunks de OCR existentes
    merged_chunks = ocr_chunks.copy()
    
    # Agregar chunks de tablas con IDs √∫nicos
    for i, table_chunk in enumerate(table_chunks):
        # Asegurar ID √∫nico
        table_chunk['id'] = f"table_enhanced_{i}"
        
        # Mantener formato compatible con sistema de b√∫squeda
        if 'content' in table_chunk and 'texto' not in table_chunk:
            table_chunk['texto'] = table_chunk['content']
        
        if 'metadata' in table_chunk and 'metadatos' not in table_chunk:
            table_chunk['metadatos'] = table_chunk['metadata']
        
        # Agregar marcadores para identificar origen
        table_chunk['metadatos']['enhanced_extraction'] = True
        table_chunk['metadatos']['chunk_source'] = 'table_extraction'
        
        merged_chunks.append(table_chunk)
    
    logger.info(f"‚úÖ {len(merged_chunks)} chunks fusionados")
    return merged_chunks

def validate_target_amounts(chunks: List[Dict]) -> Dict[str, Any]:
    """Validar que se encontraron los montos objetivo"""
    
    target_amounts = {
        'S/ 380': {'found': False, 'chunks': []},
        'S/ 320': {'found': False, 'chunks': []},
        'S/ 30': {'found': False, 'chunks': []}
    }
    
    # Buscar en todos los chunks
    for chunk in chunks:
        chunk_text = ""
        
        # Obtener texto del chunk
        if 'texto' in chunk:
            chunk_text = chunk.get('texto', '')
        elif 'content' in chunk:
            chunk_text = chunk.get('content', '')
        
        # Buscar montos objetivo
        for target in target_amounts:
            if target in chunk_text or target.replace('S/ ', '') in chunk_text:
                target_amounts[target]['found'] = True
                target_amounts[target]['chunks'].append({
                    'chunk_id': chunk.get('id', chunk.get('chunk_id', 'unknown')),
                    'extraction_method': chunk.get('metadatos', {}).get('extraction_method', 'unknown'),
                    'confidence': chunk.get('metadatos', {}).get('confidence', 0.5)
                })
    
    # Calcular estad√≠sticas
    found_count = sum(1 for target in target_amounts.values() if target['found'])
    success_rate = found_count / len(target_amounts)
    
    validation_result = {
        'targets': target_amounts,
        'found_count': found_count,
        'total_targets': len(target_amounts),
        'success_rate': success_rate,
        'validation_passed': success_rate >= 0.6  # Al menos 2 de 3 montos
    }
    
    # Log resultados
    logger.info(f"üéØ Validaci√≥n de montos objetivo:")
    for target, info in target_amounts.items():
        status = "‚úÖ" if info['found'] else "‚ùå"
        logger.info(f"   {status} {target}: {len(info['chunks'])} chunks")
    
    logger.info(f"üìä Tasa de √©xito: {success_rate:.1%} ({found_count}/{len(target_amounts)})")
    
    return validation_result

def generate_extraction_report(pdf_path: str, ocr_chunks: int, table_chunks: int, 
                             total_chunks: int, validation: Dict, extraction_time: float) -> Dict[str, Any]:
    """Generar reporte de extracci√≥n"""
    
    return {
        'pdf_file': Path(pdf_path).name,
        'pdf_path': pdf_path,
        'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
        'chunks_summary': {
            'ocr_chunks': ocr_chunks,
            'table_chunks': table_chunks,
            'total_chunks': total_chunks,
            'enhancement_ratio': f"{table_chunks}/{ocr_chunks}" if ocr_chunks > 0 else "N/A"
        },
        'extraction_performance': {
            'total_time_seconds': round(extraction_time, 3),
            'time_per_chunk': round(extraction_time / max(table_chunks, 1), 3),
            'performance_rating': 'Excelente' if extraction_time < 5 else 'Bueno' if extraction_time < 15 else 'Lento'
        },
        'validation_results': validation,
        'recommendations': generate_recommendations(validation, extraction_time)
    }

def generate_recommendations(validation: Dict, extraction_time: float) -> List[str]:
    """Generar recomendaciones basadas en resultados"""
    
    recommendations = []
    
    # Recomendaciones por validaci√≥n
    if validation['success_rate'] < 0.6:
        recommendations.append("‚ö†Ô∏è  Baja tasa de √©xito - considerar ajustar par√°metros de extracci√≥n")
        recommendations.append("üí° Revisar calidad del PDF original")
    
    if validation['success_rate'] == 1.0:
        recommendations.append("üéâ ¬°Extracci√≥n perfecta! Todos los montos objetivo encontrados")
    
    # Recomendaciones por rendimiento
    if extraction_time > 15:
        recommendations.append("‚è∞ Tiempo de extracci√≥n alto - considerar procesamiento en paralelo")
        recommendations.append("üíæ Implementar cach√© para PDFs ya procesados")
    
    if extraction_time < 2:
        recommendations.append("‚ö° Excelente rendimiento de extracci√≥n")
    
    # Recomendaciones generales
    if not recommendations:
        recommendations.append("‚úÖ Extracci√≥n exitosa sin problemas detectados")
    
    return recommendations

def test_extraction_performance(pdf_path: str) -> Dict[str, Any]:
    """Test realista considerando pre-procesamiento"""
    
    logger.info(f"üß™ Iniciando test de rendimiento para: {pdf_path}")
    
    try:
        # Informaci√≥n del PDF
        import fitz  # PyMuPDF
        doc = fitz.open(pdf_path)
        num_pages = len(doc)
        doc.close()
        
        file_size_mb = Path(pdf_path).stat().st_size / (1024 * 1024)
        
        logger.info(f"üìÑ PDF: {num_pages} p√°ginas, {file_size_mb:.1f} MB")
        
        # Test con diferentes m√©todos si Camelot est√° disponible
        timings = {}
        montos_encontrados = set()
        
        try:
            import camelot
            
            # 1. Sin pre-procesamiento (PDFs digitales)
            start = time.time()
            tables_digital = camelot.read_pdf(pdf_path, flavor='stream', pages='all')
            timings['digital'] = (time.time() - start) / max(num_pages, 1)
            
            # 2. Con pre-procesamiento (PDFs escaneados)
            start = time.time()
            tables_scanned = camelot.read_pdf(pdf_path, flavor='lattice', pages='all')
            timings['scanned'] = (time.time() - start) / max(num_pages, 1)
            
            # 3. Verificar montos espec√≠ficos
            montos_objetivo = ['S/ 380', 'S/ 320', 'S/ 30']
            
            for table in list(tables_digital) + list(tables_scanned):
                df = table.df
                for value in df.values.flatten():
                    str_val = str(value).strip()
                    if 'S/' in str_val or any(monto.replace('S/ ', '') in str_val for monto in montos_objetivo):
                        montos_encontrados.add(str_val)
            
        except ImportError:
            logger.warning("Camelot no disponible - usando extractor robusto")
            
            # Usar nuestro extractor robusto
            start = time.time()
            result = enhanced_extraction(pdf_path)
            extraction_time = time.time() - start
            
            timings['robust_extractor'] = extraction_time / max(num_pages, 1)
            
            if result.get('validation'):
                for target, info in result['validation']['targets'].items():
                    if info['found']:
                        montos_encontrados.add(target)
        
        # Resultados
        results = {
            'pdf_info': {
                'pages': num_pages,
                'size_mb': file_size_mb
            },
            'performance': timings,
            'amounts_found': list(montos_encontrados),
            'validation': {
                'S/ 380': 'S/ 380' in ' '.join(montos_encontrados) or '380' in ' '.join(montos_encontrados),
                'S/ 320': 'S/ 320' in ' '.join(montos_encontrados) or '320' in ' '.join(montos_encontrados),
                'S/ 30': 'S/ 30' in ' '.join(montos_encontrados) or '30' in ' '.join(montos_encontrados)
            }
        }
        
        # Log resultados
        logger.info(f"üìä RESULTADOS PARA {num_pages} P√ÅGINAS:")
        for method, time_per_page in timings.items():
            logger.info(f"‚è±Ô∏è  {method}: {time_per_page:.3f}s/p√°gina")
        
        logger.info(f"‚úÖ Montos encontrados: {montos_encontrados}")
        
        # Validaci√≥n
        montos_objetivo = ['S/ 380', 'S/ 320', 'S/ 30']
        for monto in montos_objetivo:
            if results['validation'].get(monto.replace('S/ ', '')) or any(monto in m for m in montos_encontrados):
                logger.info(f"‚úÖ {monto} encontrado")
            else:
                logger.warning(f"‚ùå {monto} NO encontrado - REVISAR PAR√ÅMETROS")
        
        # Advertencia si es muy lento
        if timings and min(timings.values()) > 0.5:
            logger.warning("‚ö†Ô∏è  ADVERTENCIA: Excede 500ms/p√°gina")
            logger.info("   Sugerencias:")
            logger.info("   - Procesar en paralelo")
            logger.info("   - Reducir calidad de pre-procesamiento")
            logger.info("   - Usar cach√© para PDFs ya procesados")
        
        return results
        
    except Exception as e:
        logger.error(f"‚ùå Error en test de rendimiento: {e}")
        return {"error": str(e)}

def main():
    """Funci√≥n principal del script"""
    
    parser = argparse.ArgumentParser(description='Extracci√≥n mejorada de tablas con validaci√≥n de montos')
    parser.add_argument('--pdf', required=True, help='Ruta al archivo PDF')
    parser.add_argument('--validate-montos', action='store_true', help='Validar montos espec√≠ficos')
    parser.add_argument('--test-performance', action='store_true', help='Ejecutar test de rendimiento')
    parser.add_argument('--output', help='Archivo de salida JSON (opcional)')
    parser.add_argument('--verbose', '-v', action='store_true', help='Logging detallado')
    
    args = parser.parse_args()
    
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # Verificar archivo PDF
    if not Path(args.pdf).exists():
        logger.error(f"‚ùå Archivo no encontrado: {args.pdf}")
        return 1
    
    try:
        # Test de rendimiento
        if args.test_performance:
            logger.info("üß™ Ejecutando test de rendimiento...")
            performance_results = test_extraction_performance(args.pdf)
            
            print("\n" + "="*60)
            print("üìä RESULTADOS DEL TEST DE RENDIMIENTO")
            print("="*60)
            print(json.dumps(performance_results, indent=2, ensure_ascii=False))
        
        # Extracci√≥n principal
        logger.info("üöÄ Ejecutando extracci√≥n mejorada...")
        results = enhanced_extraction(args.pdf)
        
        if results.get('error'):
            logger.error(f"‚ùå Error en extracci√≥n: {results['error']}")
            return 1
        
        # Mostrar resultados
        print("\n" + "="*60)
        print("üìã RESULTADOS DE EXTRACCI√ìN MEJORADA")
        print("="*60)
        
        print(f"üìÑ Archivo: {Path(args.pdf).name}")
        print(f"üìä Chunks totales: {results['stats']['total_chunks']}")
        print(f"‚è±Ô∏è  Tiempo: {results['stats']['extraction_time']:.3f}s")
        
        if args.validate_montos:
            validation = results['validation']
            print(f"\nüéØ VALIDACI√ìN DE MONTOS:")
            print(f"   Encontrados: {validation['found_count']}/{validation['total_targets']}")
            print(f"   Tasa de √©xito: {validation['success_rate']:.1%}")
            
            for target, info in validation['targets'].items():
                status = "‚úÖ" if info['found'] else "‚ùå"
                print(f"   {status} {target}: {len(info['chunks'])} chunks")
        
        # Guardar resultados si se especifica
        if args.output:
            with open(args.output, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
            logger.info(f"üíæ Resultados guardados en: {args.output}")
        
        print("\n‚úÖ Extracci√≥n completada exitosamente")
        return 0
        
    except Exception as e:
        logger.error(f"‚ùå Error inesperado: {e}")
        return 1

if __name__ == '__main__':
    exit(main()) 